{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кредитный скоринг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Содержание\n",
    "* Задача кредитного скоринга\n",
    "* Метрики бинарной задачи классификации\n",
    "* Проблема переобучения и схемы валидации\n",
    "* Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Кредит\n",
    "\n",
    "* Заявитель заполняет анкету\n",
    "* Банк принимает решение\n",
    "* Клиент пользуется кредитом\n",
    "* Клиент возвращает долг или не возвращает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Специфика задачи кредитного скоринга\n",
    "\n",
    "* Классы “good” и “bad” неразделимы\n",
    "* Предсказание поведения человека\n",
    "* Долгосрочное прогнозирование\n",
    "* Большая цена ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# История кредитного скоринга\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Дополнительные сервисы\n",
    "\n",
    "* Автоматизация процесса принятия решения\n",
    "* Решение принимается за секунды\n",
    "* Используется множество источников информации\n",
    "* Сформирован рынок продажи информации для банков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Примеры задач\n",
    "\n",
    "* Application scoring\n",
    "* Behavior scoring\n",
    "* Collection scoring\n",
    "* Marketing\n",
    "* Churn analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Формализация задачи\n",
    "\n",
    "* Конечная выборка размера n.\n",
    "* $X_i$ – вектор признаков.\n",
    "* $y_i$ – бинарная целевая переменная.\n",
    "* $(X_i, y_i)$ - независимые одинаково распределенные наблюдения.\n",
    "* Необходимо найти функцию $S(X) ≃ \\mathbb{P}(y = 1| X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Метрики качества\n",
    "\n",
    "* MSE (Mean square error)\n",
    "* logloss (log-Likelihood)\n",
    "* AUC (Area under the ROC curve)\n",
    "* IV (Information Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Среднеквадратичное отклонение\n",
    "* MSE (Mean square error)  \n",
    "  $\\mathbb{E}[(y - S(X))^2]$\n",
    "\n",
    "* Оптимальное значение  \n",
    "  $S(X) = \\mathbb{P}(y = 1| X)$\n",
    "\n",
    "* Оценка  \n",
    "  $\\frac{1}{n}\\sum_{i=1}^n[(y_i - S(X_i))^2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Правдоподобие\n",
    "\n",
    "* logloss (log-Likelihood)  \n",
    "  $logloss = -\\mathbb{E}[y \\ln(S(X)) + (1-y)\\ln(1 - S(X))]$\n",
    "\n",
    "* Оптимальное значение  \n",
    "  $S(X) = \\mathbb{P}(y = 1| X)$\n",
    "\n",
    "* Оценка  \n",
    "  $\\frac{1}{n}\\sum_{i=1}^n[y_i \\ln(S(X_i)) + (1-y_i)\\ln(1 - S(X_i))]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Свойства Правдоподобия\n",
    "\n",
    "* Если искомая зависимость принадлежит заранее известному классу функций, то оценка в максимума правдоподобия в этом классе обладает свойствами несмещенности, состоятельности и эффективности.  \n",
    "  $\\theta_{MML} = argmin_{\\theta}(logloss(y, S(X, \\theta)))$\n",
    "  \n",
    "* Добавление “бесполезных” степеней свободы в класс функции уменьшает оптимальное значение logloss-а на случайную величину, распределенную пропорцианально $\\chi^2$. Это позволяет проверять гипотезы о бесполезности наборов признаков.  \n",
    "  $2n[\\hat{logloss}(\\hat{\\theta_1}) - \\hat{logloss}(\\hat{\\theta_2, \\hat{\\alpha}})] \\sim \\chi^2(dim(\\alpha))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# AUC\n",
    "\n",
    "* AUC (Area under the ROC curve)  \n",
    "  $AUC = \\mathbb{P}(S(X_1) > S(X_2) | y_1 = 1, y_2 = 0) + \\frac{1}{2}\\mathbb{P}(S(X_1) = S(X_2) | y_1 = 1, y_2 = 0)$\n",
    "\n",
    "* Оптимальное значение уже неоднозначно, но содержит искомую зависимость.  \n",
    "  $S(X) = \\mathbb{P}(y = 1| X)$\n",
    "\n",
    "* Оценка  \n",
    "  $\\frac{1}{\\sum[y_i = 1]\\sum[y_i = 0]}\\left[ \\sum_{y_i=1 ,y_j=0}[S(X_i) > S(X_j)] + \\frac{1}{2}\\sum_{y_i=1 ,y_j=0}[S(X_i) = S(X_j)]\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Свойства AUC\n",
    "* Не меняется при неубывающем преобразовании скор балла  \n",
    "  ${AUC}_{f(S)} = {AUC}_{S},$ если $f(S)$ - строго возрастающая функция\n",
    "* Ограничена 0, 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Receiver Operating Characteristic ROC-curve\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_roc_001.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* True Positive Rate - Доля верных положительных классификаций $\\frac{\\sum_i[S(X_i) \\ge \\text{cut-off}, y_i = 1]}{\\sum_i[y_i = 1]}$\n",
    "* False Positive Rate - Доля ложных положительных классификаций\n",
    "$\\frac{\\sum_i[S(X_i) < \\text{cut-off}, y_i = 0]}{\\sum_i[y_i = 0]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Information Value\n",
    "\n",
    "* IV (Information Value)\n",
    "  $IV = \\int \\left[\\left(p_S(s|y=1) - p_S(s|y=0)\\right)ln\\left(\\frac{p_S(s|y=1)}{p_S(s|y=0)}\\right) \\right]$\n",
    "  \n",
    "* Оптимальное значение  \n",
    "  $S(X) = \\mathbb{P}(y = 1| X)$\n",
    "  \n",
    "* Оценка получается через оценки плотности для условных распределений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Свойства Information Value\n",
    "\n",
    "* Не отрицательность  \n",
    "  $IV \\ge 0$\n",
    "* Не увеличивается при преобразовании скор балла  \n",
    "  $IV_{f(S)} \\le IV_S$\n",
    "* Аддитивность условно независимых признаков  \n",
    "  $IV_{(x_1, ..., x_k)} = IV_{x_1} + ... + IV_{x_k}$, где $x_1, ..., x_k$ независимы при условии $y=1$ и $y=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Использование метрик\n",
    "* Все рассмотренные метрики достигают оптимальных значений при $S(X) = \\mathbb{P}(y = 1| X)$.\n",
    "* Минимизировать удобнее log-loss.\n",
    "* Если важен только порядок, в котором упорядочены объекты по степени принадлежности классам, то используем AUC, как критерий качества.\n",
    "* Если нужно оценить предсказательную силу отдельного признака, то удобно использовать IV.\n",
    "* В случае, если нужно производить оценку не зависящую от сбалансированности классов, то подходят AUC и IV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Проблема переобучения\n",
    "\n",
    "* Наша задача – поиск $S(X) = \\mathbb{P}(y = 1| X)$.\n",
    "* Поэтому мы будем минимизировать вероятностную характеристику:  \n",
    "  $-LL = -\\mathbb{E}[y \\ln(S(X)) + (1-y)\\ln(1 - S(X))]$\n",
    "* Но по факту мы можем минимизировать только оценку:  \n",
    "  $\\frac{1}{n}\\sum_{i=1}^n[y_i \\ln(S(X_i)) + (1-y_i)\\ln(1 - S(X_i))]$\n",
    "* При выборе функции, которая минимизирует оценку, пропадает ее несмещенность. Оценка становится “оптимистичнее”. И чем “шире” класс функций для поиска – тем выше “оптимистичность”.\n",
    "* Чтобы получить несмещенную – можно использовать отложенную выборку, которая не использовалась в обучении для выбора функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Схемы валидации\n",
    "* Train/ Validate. В случае, если со временем меняется зависимость (распределение пар $(X_i, y_i)$), удобно использовать в качестве валидации самую последнюю часть выборки.  \n",
    "  \n",
    "* Cross-Validation. Позволяет повысить точность оценки качества предсказания за счет использования всей выборки для валидации. Хорошо подходит для детектирования маленьких улучшений модели.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Наивный Байесовский Классификатор\n",
    "* Путь набор признаков $X^1, ..., X^k$ независим при условии $y=1$ и $y=0$.  \n",
    "  $$\\mathbb{P}(X=x|y=1) = \\mathbb{P}(X^1=x^1|y=1) \\cdot ... \\cdot \\mathbb{P}(X^k=x^k|y=1)\\\\  \n",
    "    \\mathbb{P}(X=x|y=0) = \\mathbb{P}(X^1=x^1|y=0) \\cdot ... \\cdot \\mathbb{P}(X^k=x^k|y=0)$$\n",
    "* Тогда с помощью формулы Байеса можно вывести формулу для вероятности события $y=1$ при условии $X$.  \n",
    "  $$\\mathbb{P}(y=1|X=x) = \\frac{1}{1 + exp(-logit(x))},\\\\\n",
    "  logit(x) = \\ln\\left(\\frac{\\mathbb{P}(y=1)}{\\mathbb{P}(y=0)}\\right) + WoE^1(x^1) + ... + WoE^k(x^k),\\\\\n",
    "  WoE^j(x^j) = \\ln\\left(\\frac{\\mathbb{P}(X^j=x^j|y=1)}{\\mathbb{P}(X^j=x^j|y=0)}\\right).$$\n",
    "  \n",
    "* Для настройки классификатора достаточно оценить функции $WoE^j(x^j)$ или что то же самое, оценить условные плотности признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Логистическая регрессия\n",
    "\n",
    "* Формула\n",
    "  $$\\mathbb{P}(y=1|X=x) = \\frac{1}{1 + exp(-logit(x, w))},$$  \n",
    "  $$logit(x, w) = w^0 + w^1 x^1 + ... w^k x^k$$  \n",
    "* Минимизируем logloss на обучающей выборке, подбирая веса $w$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Преобразование признаков\n",
    "Для улучшение работы линейных моделей есть несколько техник нормализации признаков.\n",
    "\n",
    "* Нормализация WoE. Вместо признака $x^j$ использовать $WoE^j(x^j)$, тогда класс линейных функций будет содержать наивный байесовский классификатор.\n",
    "* Преобразование Бокса-Кокса признаков к более нормальному распределению.  \n",
    "  $x_{a, \\lambda} = \\begin{cases}\n",
    "                        \\frac{(x + a)^{\\lambda} - 1}{\\lambda}, \\lambda \\ne 0 \\\\\n",
    "                        log(x + a), \\lambda = 0 \\\\\n",
    "                    \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Регуляризация\n",
    "\n",
    "Для борьбы с переобучением используются несколько стандартных способов регуляризации.\n",
    "\n",
    "* Lasso (L1)  \n",
    "  $\\hat{w} = {argmin}_{w}\\left(logloss + C \\cdot |w|_1\\right)$  \n",
    "* Ridge (L2)  \n",
    "  $\\hat{w} = {argmin}_{w}\\left(logloss + C \\cdot |w|_2\\right)$\n",
    "* Elastic net  \n",
    "  $\\hat{w} = {argmin}_{w}\\left(logloss + C_1 \\cdot |w|_1 + C_2 \\cdot |w|_2\\right)$\n",
    "* Статистический отбор признаков. Forward, Backward, Stepwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Резюме\n",
    "* Задача кредитного скоринга имеет ряд специфических свойств:\n",
    "    * Долгосрочное прогнозирование\n",
    "    * Предсказание поведения людей\n",
    "    * Зависимость меняется со временем\n",
    "* Различные метрики качества\n",
    "    * Log-loss – удобен для оптимизации\n",
    "    * AUC - подходит для критерия качества\n",
    "    * IV – для оценки предсказательной силы признаков\n",
    "* Выбор схемы валидации\n",
    "    * Train/ Validate - при изменении зависимость во времени\n",
    "    * Cross-Validation – для увеличения точности оценки и стабильной зависимости\n",
    "* Логистическая регрессия\n",
    "    * Обобщение Наивного Байесовского классификатора\n",
    "    * Важна нормализация признаков в терминах WoE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
